{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "445df8c8",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e50fc83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e9ad59",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddae8479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skewCorrection(img, SKEW_RESULTS=True):\n",
    "    \"\"\"\n",
    "    img : Grey/Binary image\n",
    "    HOUHG_RESULTS : For displaying hough transform results\n",
    "    \"\"\"\n",
    "    #Hough Transform\n",
    "    \n",
    "    # Perform edge detection using the Canny algorithm\n",
    "    edges = cv.Canny(img, 50, 150, apertureSize=3)\n",
    "    \n",
    "    # Apply the Hough Transform to detect lines\n",
    "    # The second and third arguments are the rho and theta resolutions\n",
    "    # The fourth argument is the threshold for line detection\n",
    "    lines = cv.HoughLines(edges, 1, np.pi / 180, 50)\n",
    "    \n",
    "    \n",
    "    #Skew correction\n",
    "    \n",
    "    #calculate the avg angle of the detected lines\n",
    "    try:\n",
    "        angles = []\n",
    "        for line in lines:\n",
    "            rho, theta = line[0]\n",
    "            angle = (theta * 180)/np.pi\n",
    "            angles.append(angle)\n",
    "\n",
    "        # Calculate the median angle and correct the skew\n",
    "        median_angle = np.median(angles)\n",
    "        # Subtract 90 to obtain the skew angle\n",
    "        rotation_angle = median_angle - 90\n",
    "\n",
    "        #Center of image\n",
    "        height, width = img.shape[:2]\n",
    "        center = (width//2, height//2)\n",
    "\n",
    "        # Rotate the original image using the calculated angle\n",
    "        rotation_matrix = cv.getRotationMatrix2D(center, rotation_angle, 1)\n",
    "        rotated_img = cv.warpAffine(img, rotation_matrix, (width, height), borderValue=(255, 255, 255))\n",
    "    except TypeError:\n",
    "        rotated_img = img\n",
    "\n",
    "    \n",
    "    if (SKEW_RESULTS):\n",
    "        print(f\"No. of lines Detected: {lines.shape[0]}\")\n",
    "\n",
    "        # Draw the detected median lines on the original image\n",
    "        \n",
    "        # Find the index of the angle closest to the median_angle\n",
    "        closest_angle_index = np.argmin(np.abs(np.array(angles) - median_angle))\n",
    "\n",
    "        # Retrieve the corresponding rho and theta values\n",
    "        rho, theta = lines[closest_angle_index][0]\n",
    "        \n",
    "        # For convreting polar co-ordinates to cartesian co-ordinates\n",
    "        a = np.cos(theta)\n",
    "        b = np.sin(theta)\n",
    "        x0 = a * rho\n",
    "        y0 = b * rho\n",
    "        # pts in perpendicular direction of the reference pt(x0,y0) for making a line segment\n",
    "        x1 = int(x0 + 1000 * (-b))\n",
    "        y1 = int(y0 + 1000 * (a))\n",
    "        x2 = int(x0 - 1000 * (-b))\n",
    "        y2 = int(y0 - 1000 * (a))\n",
    "        cv.line(img, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "        \n",
    "#         plt.figure(figsize=(20,10))\n",
    "#         plt.subplot(2,2,1)\n",
    "#         plt.imshow(img, cmap=\"gray\")\n",
    "#         plt.axis(\"off\")\n",
    "\n",
    "#         plt.subplot(2,2,2)\n",
    "#         plt.imshow(edges, cmap=\"gray\")\n",
    "#         plt.title(\"Canny Edges\")\n",
    "#         plt.axis(\"off\")\n",
    "#         plt.show()\n",
    "        \n",
    "#         plt.subplot(2,2,3)\n",
    "#         plt.imshow(rotated_img, cmap=\"gray\")\n",
    "#         plt.title(\"Unskewed Image\", fontsize=8)\n",
    "#         plt.axis(\"off\")\n",
    "#         plt.show()\n",
    "        \n",
    "    return rotated_img\n",
    "\n",
    "def imagePre(img_locs):\n",
    "    \n",
    "    for loc in img_locs:\n",
    "    \n",
    "        #Load the image\n",
    "        img = cv.imread(loc)\n",
    "\n",
    "        #Greyscale \n",
    "        grey_img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "        #No resizing(Already taken care by doctr apparently :/)\n",
    "\n",
    "        # Apply thresholding to convert the image to binary\n",
    "        #returns threshold val and binary image\n",
    "        binary_img = cv.threshold(grey_img, 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)[1]\n",
    "\n",
    "        #erosion operation is typically used to fill small gaps in the objects, \n",
    "        kernel = cv.getStructuringElement(cv.MORPH_RECT, (5,5))\n",
    "        erosion = cv.erode(binary_img, kernel, iterations = 1)\n",
    "\n",
    "\n",
    "        unskewed_img = skewCorrection(erosion, False)\n",
    "\n",
    "\n",
    "        #Standardize the image\n",
    "#         mean = np.mean(unskewed_img)\n",
    "#         std = np.std(unskewed_img)\n",
    "\n",
    "#         std_img = (unskewed_img - mean)/std\n",
    "\n",
    "        yield unskewed_img\n",
    "    \n",
    "    \n",
    "def make_dataset(src_dir, df, dest_dir=\"../data/trainset\", no_of_examples=None):\n",
    "    \n",
    "    if no_of_examples == None:\n",
    "        no_of_examples=len(df[\"files\"])\n",
    "\n",
    "    img_folder = os.path.join(dest_dir, \"images\")\n",
    "    if not os.path.exists(img_folder):\n",
    "        os.makedirs(img_folder)\n",
    "\n",
    "    values = {}\n",
    "    count = 1\n",
    "    for index, row in tqdm(islice(df.iterrows(), no_of_examples), total = no_of_examples, desc = \"Progress\"):\n",
    "        img_loc = os.path.join(src_dir, row[\"files\"])\n",
    "        \n",
    "        std_img = next(imagePre([img_loc]))\n",
    "        \n",
    "\n",
    "        #New filename\n",
    "        new_filename = f\"img_{count}.jpg\"\n",
    "\n",
    "        new_img_loc = os.path.join(img_folder, new_filename)\n",
    "    \n",
    "        #Copying all the files to training set\n",
    "#         shutil.copy(img_loc, new_img_loc)\n",
    "\n",
    "        # saving all the pre processed image to training set\n",
    "        cv.imwrite(new_img_loc, std_img)\n",
    "\n",
    "        values[new_filename] = row[\"tokens\"]\n",
    "        count += 1\n",
    "        \n",
    "        #Making json file\n",
    "        json_filename = \"labels.json\"\n",
    "\n",
    "        json_loc = os.path.join(dest_dir, json_filename)\n",
    "\n",
    "        with open(json_loc, \"w\", encoding='utf-8') as f:\n",
    "            json.dump(values, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a1f0fd",
   "metadata": {},
   "source": [
    "## Location of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73d99557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter location to Data Folder : ./../data/devanagari/trainset/\n",
      "Data Folder : ['images', '.DS_Store', 'labels.json', 'unique_words.txt', 'vocab.txt', 'train.txt']\n"
     ]
    }
   ],
   "source": [
    "#Take data folder location as input\n",
    "src_dir = input(\"Enter location to Data Folder : \")\n",
    "\n",
    "if os.path.exists(src_dir):\n",
    "    dir_ = os.listdir(src_dir)\n",
    "    print(f\"Data Folder : {dir_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22391f0d",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86bdde7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = '/data/BADRI/IHTR/trainset/devanagari/'\n",
    "dest_dir = './../data/devanagari/trainset_processed/'\n",
    "\n",
    "with open(train_data + 'labels.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    \n",
    "train_df = pd.DataFrame.from_dict(data, orient='index').reset_index()\n",
    "train_df.columns = ['files','tokens']\n",
    "\n",
    "if not os.path.exists(dest_dir):\n",
    "    os.makedirs(dest_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac06bcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_df = train_df.loc[0:100, \"files\"]\n",
    "img_locs = list(slice_df)\n",
    "\n",
    "img_locs = [os.path.join(train_data + 'images/', loc) for loc in img_locs]\n",
    "\n",
    "# img_locs = img_locs[0]\n",
    "# print(img_locs)\n",
    "\n",
    "img_gen = imagePre(img_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f6c119",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                  | 47983/69853 [32:31<23:54, 15.24it/s]"
     ]
    }
   ],
   "source": [
    "#Making Training Dataset\n",
    "make_dataset(src_dir=train_data + 'images/', dest_dir=dest_dir, df=train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3a9d369",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:02<00:00, 417.86it/s]\n"
     ]
    }
   ],
   "source": [
    "#Making validation Dataset\n",
    "make_dataset(src_dir=src_dir, dest_dir=dest_dir, df=val_df, no_of_examples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d627999",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
